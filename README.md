YouTube Comment Sentiment Analyzer (Chrome Extension + FastAPI Backend)

This project lets you analyze sentiment of YouTube comments using a Chrome Extension and an ML model served through FastAPI.

You get:
	â€¢	âœ… A Chrome extension UI
	â€¢	âœ… A FastAPI backend for predictions
	â€¢	âœ… MLflow-tracked model (TF-IDF + LightGBM)
	â€¢	âœ… Extra features: wordcloud, charts, trend graphs

Everything can be run locally and for free â€” no Chrome Web Store fees and no AWS cost required.

â¸»

ğŸš€ Features
	â€¢	âœ… Analyze YouTube comments in one click
	â€¢	âœ… Sentiment prediction (Positive / Neutral / Negative)
	â€¢	âœ… Wordcloud generation
	â€¢	âœ… Pie chart summarizing sentiment
	â€¢	âœ… Timestamp-wise trend graph
	â€¢	âœ… Backend powered by FastAPI + MLflow + LightGBM
	â€¢	âœ… No need to publish to Chrome Web Store

â¸»

ğŸ“Œ Project Structure
.
â”œâ”€â”€ frontend/               # Chrome extension UI
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ popup.html
â”‚   â”œâ”€â”€ popup.js
â”‚
â”œâ”€â”€ FastAPI/                # Backend API
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl (downloaded automatically OR included)
â”‚
â””â”€â”€ README.md


âœ… Cloud Deployment (AWS)

This project was also fully deployed on AWS as part of the CI/CD pipeline and backend hosting.
I used the following AWS services:
	â€¢	EC2 â€“ hosted the FastAPI backend and ran the ML model in a production-like environment.
	â€¢	S3 â€“ stored model artifacts, TF-IDF vectorizer, and deployment bundles for CodeDeploy.
	â€¢	ECR â€“ stored the Docker images of the FastAPI application created by GitHub Actions CI/CD.
	â€¢	Auto Scaling Group (ASG) â€“ ensured multiple EC2 instances could run the backend for scalability and reliability.
	â€¢	Application Load Balancer (ALB) â€“ routed traffic to the healthy backend instances.
	â€¢	CodeDeploy â€“ performed zero-downtime deployments from GitHub Actions to the EC2 instances.

This created a complete real-world pipeline:
model training â†’ MLflow logging â†’ GitHub Actions CI/CD â†’ Docker build â†’ ECR push â†’ S3 bundle â†’ CodeDeploy â†’ ASG rollout.

âš ï¸ Why the AWS server is not currently running

Running EC2 instances, ALBs, and ASGs continuously would incur monthly charges, so I have disabled the live server to avoid costs.
However, the full AWS infrastructure, deployment pipeline, and containerized backend are implemented, and the architecture is documented for review.
The project can be run fully locally for free using the instructions above.

â¸»

If you want, I can add:

âœ… A full AWS architecture diagram
âœ… A section in the README titled â€œArchitecture Overviewâ€
âœ… A badge like â€œâœ… Full CI/CD with AWS + GitHub Actionsâ€
âœ… A short resume bullet describing this project for your job applications


ğŸ§© 1. How to Install the Chrome Extension (No Web Store Needed)

Chrome allows you to load extensions manually.

âœ… Steps
	1.	Download or clone this repository.
	2.	Open Chrome and go to: chrome://extensions/
  3.	Turn on Developer Mode (top right).
	4.	Click Load Unpacked.
	5.	Select the frontend/ folder.

The extension will now appear in your Chrome toolbar.
âš™ï¸ 2. How to Run the FastAPI Backend Locally (Free)

The backend provides the ML predictions and analysis features.
You can run it on your own laptop.

âœ… Install dependencies
cd FastAPI
pip install -r requirements.txt

âœ… Start the API server
uvicorn app:app --host 0.0.0.0 --port 8000

Your backend will now be live at:
http://localhost:8000

âœ… Make sure popup.js points to your backend

In frontend/popup.js, look for: const API_URL = "http://localhost:8000";
Make sure this matches your local FastAPI URL.

Optional: Expose API to the Internet (Free)
If you want the Chrome extension to work without running locally, you can temporarily host FastAPI using ngrok. This gives you a public URL like: https://abcd1234.ngrok.io
Update API_URL in popup.js, and your extension will work globally.

ğŸ§  ML Model Overview

This project uses:
	â€¢	TF-IDF Vectorizer
	â€¢	LightGBM Classifier
	â€¢	Registered & versioned with MLflow Model Registry

The backend:
	â€¢	Preprocesses comment text
	â€¢	Transforms it using the stored TF-IDF vectorizer
	â€¢	Predicts sentiment using the MLflow model
	â€¢	Returns a clean JSON response

ğŸ“ I have two more repos which comes under the umbrella of this project:
1. yt-comment-sentiment-analysis (Main Project Repo â€” FastAPI Backend)

This repository contains:
	â€¢	The FastAPI application (app.py)
	â€¢	The Dockerfile used for containerizing the backend
	â€¢	The CI/CD workflow (cicd.yaml)
	â€¢	All deployment scripts used by CodeDeploy
	â€¢	The frontend Chrome extension files (manifest.json, popup.html, popup.js)
	â€¢	The logic for preprocessing, prediction, charting, and trend analysis

This is the repo users can clone to run the entire system locally.


2. Youtube_Comment_Analyzer (ML Experiments + Model Training)

This repository contains:
	â€¢	All experiments with different ML algorithms
	â€¢	Training notebooks for Logistic Regression, SVM, Naive Bayes, LightGBM, etc.
	â€¢	MLflow tracking and logging setup
	â€¢	Model versions & metrics logged to MLflow
	â€¢	Code for TF-IDF vectorizer training and experiment comparisons

This repo documents how the final production model was built, tested, and selected.


ğŸ“¡ API Endpoints
Endpoint                                Description
/predict                                Predict sentiment for a list of comments
/predict_with_timestamps                Predict + return timestamps
/generate_chart                         Pie chart of sentiments
/generate_wordcloud                     Wordcloud image
/generate_trend_graph                   Monthly sentiment trend

ğŸ“ Notes
	â€¢	You do not need to publish the extension to Chrome Web Store.
	â€¢	You do not need AWS or paid hosting.
	â€¢	Running the backend locally is enough for demonstration and portfolio use.

